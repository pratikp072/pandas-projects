{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "171dd251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83f49c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   account_id            txn_time    amount txn_type    description       city\n",
      "0       10008 2024-01-03 02:00:00   6939.97   credit       atm cash     Mumbai\n",
      "1       10026 2024-01-10 06:00:00     50.00    debit   upi transfer       Pune\n",
      "2       10019 2024-01-11 20:00:00     50.00    debit  salary credit       Pune\n",
      "3       10026 2024-01-16 15:00:00   1109.54    debit       loan emi      Delhi\n",
      "4       10017 2024-01-17 15:00:00  22027.76    debit   upi transfer  Hyderabad\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   account_id   120 non-null    int64         \n",
      " 1   txn_time     120 non-null    datetime64[ns]\n",
      " 2   amount       120 non-null    float64       \n",
      " 3   txn_type     120 non-null    string        \n",
      " 4   description  120 non-null    string        \n",
      " 5   city         120 non-null    string        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), string(3)\n",
      "memory usage: 5.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Determine the base directory depending on whether we're in a notebook or a .py file\n",
    "BASE_DIR = Path(__file__).parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "\n",
    "# Path to the CSV file\n",
    "CSV_PATH = BASE_DIR / \"data\" / \"transactions.csv\"\n",
    "\n",
    "# Check if the CSV exists\n",
    "if not CSV_PATH.exists():\n",
    "    raise FileNotFoundError(f\"CSV file not found: {CSV_PATH}\")\n",
    "\n",
    "OUT_DIR = BASE_DIR / \"outputs\" \n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(\n",
    "    CSV_PATH,\n",
    "    dtype={\n",
    "        \"account_id\": \"int64\",\n",
    "        \"amount\": \"float64\",\n",
    "        \"txn_type\": \"string\",\n",
    "        \"description\": \"string\",\n",
    "        \"city\": \"string\"\n",
    "    },\n",
    "    parse_dates=[\"txn_time\"],\n",
    "    dayfirst=True  # because format is DD-MM-YYYY\n",
    ")\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b19ece9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account_id     0\n",
      "txn_time       0\n",
      "amount         0\n",
      "txn_type       0\n",
      "description    0\n",
      "city           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Basic Data Cleaning\n",
    "# Check for duplicates and missing values:\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates(subset=[\"account_id\", \"txn_time\", \"amount\", \"txn_type\", \"description\", \"city\"])\n",
    "\n",
    "# Check missing values\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Clean string columns\n",
    "for col in [\"txn_type\", \"description\", \"city\"]:\n",
    "    df[col] = df[col].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe27ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# We create new columns needed for analysis.\n",
    "\n",
    "df = df.sort_values(\"txn_time\").set_index(\"txn_time\")\n",
    "\n",
    "# Derived columns\n",
    "df[\"hour\"] = df.index.hour\n",
    "df[\"month\"] = df.index.to_period(\"M\").astype(str)  # e.g., '2024-01'\n",
    "df[\"weekday\"] = df.index.day_name()\n",
    "df[\"is_weekend\"] = df.index.weekday >= 5\n",
    "df[\"is_night\"] = (df[\"hour\"] < 6) | (df[\"hour\"] > 22)\n",
    "df[\"is_high\"] = df[\"amount\"] > 200_000\n",
    "\n",
    "# Map city to region\n",
    "city_to_region = {\n",
    "    \"Mumbai\":\"West\",\"Pune\":\"West\",\"Delhi\":\"North\",\"Bengaluru\":\"South\",\n",
    "    \"Hyderabad\":\"South\",\"Chennai\":\"South\",\"Kolkata\":\"East\"\n",
    "}\n",
    "df[\"region\"] = df[\"city\"].map(city_to_region).fillna(\"Unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a47389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core KPIs & Aggregations\n",
    "\n",
    "# Overall KPIs:\n",
    "overall = pd.DataFrame({\n",
    "    \"total_txns\": [len(df)],\n",
    "    \"total_amount\": [df[\"amount\"].sum()],\n",
    "    \"median_amount\": [df[\"amount\"].median()],\n",
    "    \"avg_amount\": [df[\"amount\"].mean()],\n",
    "    \"pct_night\": [df[\"is_night\"].mean()*100],\n",
    "    \"pct_high\": [df[\"is_high\"].mean()*100],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3247498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month-wise summary:\n",
    "monthly = df.resample(\"ME\").agg(\n",
    "    total_amount=(\"amount\",\"sum\"),\n",
    "    txns=(\"amount\",\"count\"),\n",
    "    high_txns=(\"is_high\",\"sum\"),\n",
    "    night_txns=(\"is_night\",\"sum\")\n",
    ").reset_index()\n",
    "monthly[\"month\"] = monthly[\"txn_time\"].dt.to_period(\"M\").astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b325fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# City-wise summary:\n",
    "city_perf = df.groupby(\"city\", as_index=False).agg(\n",
    "    total_amount=(\"amount\",\"sum\"),\n",
    "    txns=(\"amount\",\"count\"),\n",
    "    high_txns=(\"is_high\",\"sum\"),\n",
    "    night_txns=(\"is_night\",\"sum\")\n",
    ").sort_values(\"total_amount\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbf4bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot Tables\n",
    "# Month x City\n",
    "pivot_month_city = pd.pivot_table(df.reset_index(), index=\"month\", columns=\"city\", values=\"amount\", aggfunc=\"sum\", fill_value=0)\n",
    "\n",
    "# Transaction type per month\n",
    "pivot_month_type = pd.pivot_table(df.reset_index(), index=\"month\", columns=\"txn_type\", values=\"amount\", aggfunc=[\"sum\",\"count\"], fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fed6483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFM Analysis\n",
    "max_date = df.index.max().normalize()  # last date in dataset\n",
    "\n",
    "rfm = df.groupby(\"account_id\").agg(\n",
    "    last_txn=(\"amount\", lambda s: s.index.max()),  # last transaction\n",
    "    frequency=(\"amount\",\"count\"),\n",
    "    monetary=(\"amount\",\"sum\")\n",
    ")\n",
    "rfm[\"recency_days\"] = (max_date - rfm[\"last_txn\"].dt.normalize()).dt.days\n",
    "\n",
    "# Quartile segmentation\n",
    "rfm[\"R_quart\"] = pd.qcut(-rfm[\"recency_days\"], 4, labels=[1,2,3,4])\n",
    "rfm[\"F_quart\"] = pd.qcut(rfm[\"frequency\"].rank(method=\"first\"), 4, labels=[1,2,3,4])\n",
    "rfm[\"M_quart\"] = pd.qcut(rfm[\"monetary\"].rank(method=\"first\"), 4, labels=[1,2,3,4])\n",
    "\n",
    "rfm[\"RFM_score\"] = rfm[[\"R_quart\",\"F_quart\",\"M_quart\"]].astype(int).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3eda24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort Analysis\n",
    "x = df.reset_index()[[\"txn_time\",\"account_id\"]].copy()\n",
    "x[\"cohort_month\"] = x[\"txn_time\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "# First month per account\n",
    "first_month = x.groupby(\"account_id\")[\"cohort_month\"].min().rename(\"first_month\")\n",
    "x = x.merge(first_month, on=\"account_id\", how=\"left\")\n",
    "\n",
    "# Cohort index (months since first transaction)\n",
    "x[\"cohort_index\"] = x.apply(lambda row: (pd.Period(row[\"cohort_month\"]).year - pd.Period(row[\"first_month\"]).year)*12 + (pd.Period(row[\"cohort_month\"]).month - pd.Period(row[\"first_month\"]).month), axis=1)\n",
    "\n",
    "# Cohort retention table\n",
    "cohort_base = x.groupby(\"first_month\")[\"account_id\"].nunique()\n",
    "cohort_counts = x.groupby([\"first_month\",\"cohort_index\"])[\"account_id\"].nunique().unstack(fill_value=0)\n",
    "cohort_retention = (cohort_counts.T / cohort_base).T.round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a02c5bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Results\n",
    "excel_path = OUT_DIR / \"neopay_pandas_report.xlsx\"\n",
    "with pd.ExcelWriter(excel_path, engine=\"xlsxwriter\") as xl:\n",
    "    overall.to_excel(xl, sheet_name=\"00_overall\", index=False)\n",
    "    monthly.to_excel(xl, sheet_name=\"01_monthly\", index=False)\n",
    "    city_perf.to_excel(xl, sheet_name=\"02_city_perf\", index=False)\n",
    "    pivot_month_city.to_excel(xl, sheet_name=\"03_pivot_month_city\")\n",
    "    pivot_month_type.to_excel(xl, sheet_name=\"04_pivot_month_type\")\n",
    "    rfm.reset_index().to_excel(xl, sheet_name=\"05_rfm\", index=False)\n",
    "    cohort_retention.to_excel(xl, sheet_name=\"06_cohort_retention\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dcb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional CSVs for downstream teams\n",
    "monthly.to_csv(OUT_DIR / \"monthly_metrics.csv\", index=False)\n",
    "city_perf.to_csv(OUT_DIR / \"city_performance.csv\", index=False)\n",
    "rfm.reset_index().to_csv(OUT_DIR / \"rfm_scores.csv\", index=False)\n",
    "cohort_retention.to_csv(OUT_DIR / \"cohort_retention.csv\")\n",
    "print(\"Saved:\", excel_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
